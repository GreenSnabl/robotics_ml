{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment for practical work 4. Basics of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group:\n",
    "\n",
    "*  Jannik Bucher\n",
    "*  Dennis Imhof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dataset: Page Blocks Dataset\n",
    "[Page Blocks Dataset](https://archive.ics.uci.edu/ml/datasets/Page+Blocks+Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Assignment\n",
    "\n",
    "Before performing the practical work, you need download the data set accordingly to the option on your machine\n",
    "1. Write a program that splits the original sample into a training set and a test set (training set, validation set, test set)\n",
    "2. Build a model using Perceptron (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) and MLPClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html). On the basis of experiments, select values for learning rate, the regularization parameter, the optimization function.\n",
    "3. Build learning curves for better explanation of your experiments.\n",
    "\n",
    "## Options\n",
    "Data sets are taken from the UCI Machine Learning Repository\n",
    "https://archive.ics.uci.edu/ml/\n",
    "The option is determined by the data set, which can be downloaded from the link above:\n",
    "The option is determined by the data set, which can be downloaded from the link above:\n",
    "1. Sponge\n",
    "2. Water Treatment Plant\n",
    "3. Synthetic Control Chart Time Series\n",
    "4. Character Trajectories\n",
    "5. Plants\n",
    "6. Libras Movement\n",
    "7. KEGG Metabolic Relation Network (Directed)\n",
    "8. SMS Spam Collection\n",
    "9. seeds\n",
    "10. Human Activity Recognition Using Smartphones\n",
    "11. User Knowledge Modeling\n",
    "12. NYSK\n",
    "13. Activities of Daily Living (ADLs) Recognition Using Binary Sensors\n",
    "14. Dresses_Attribute_Sales\n",
    "15. Wholesale customers\n",
    "16. StoneFlakes\n",
    "17. Gesture Phase Segmentation\n",
    "18. AAAI 2014 Accepted Papers\n",
    "19. Dow Jones Index\n",
    "20. AAAI 2013 Accepted Papers\n",
    "21. wiki4HE\n",
    "22. Folio\n",
    "23. Mice Protein Expression\n",
    "24. Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinsonâ€™s Disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, title, X, y, param_name, param_range, scoring=\"accuracy\"):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=3, scoring=scoring, n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    \n",
    "    best_test_param = param_range[np.argmax(test_scores_mean)]\n",
    "    best_train_param = param_range[np.argmax(train_scores_mean)]\n",
    "\n",
    "    best_test_score = np.max(test_scores_mean)\n",
    "    best_train_score = np.max(train_scores_mean)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.title(\"Validation Curve {}: {} vs {}\\nBest train param: {} - score: {}\\nBest test param: {} - score {}\".format(title, \n",
    "                                                                                                                       scoring, \n",
    "                                                                                                                       param_name, \n",
    "                                                                                                                       best_train_param, \n",
    "                                                                                                                       best_train_score, \n",
    "                                                                                                                       best_test_param,\n",
    "                                                                                                                       best_test_score))\n",
    "    plt.xlabel(\"{}\".format(param_name))\n",
    "    plt.ylabel(\"{}\".format(scoring))\n",
    "    #plt.ylim(0.1, 0.4)\n",
    "    plt.axvline(best_test_param, color='darkorange', linestyle='--', label=\"best train param\")\n",
    "    plt.axvline(best_train_param, color='navy', linestyle='--', label=\"best test param\")\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page-Blocks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "with open('data/page-blocks.data') as f:\n",
    "    for l in f:       \n",
    "        elements.append([float(x) for x in l.split()])\n",
    "        \n",
    "elements = np.array(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['height', \n",
    "           'lenght', \n",
    "           'area',\n",
    "           'eccen',\n",
    "           'p_black',\n",
    "           'p_and',\n",
    "           'mean_tr',\n",
    "           'blackpix',\n",
    "           'blackand',\n",
    "           'wb_trans',\n",
    "           'block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(elements, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"block\", axis=1), df[\"block\"], train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>lenght</th>\n",
       "      <th>area</th>\n",
       "      <th>eccen</th>\n",
       "      <th>p_black</th>\n",
       "      <th>p_and</th>\n",
       "      <th>mean_tr</th>\n",
       "      <th>blackpix</th>\n",
       "      <th>blackand</th>\n",
       "      <th>wb_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "      <td>3831.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.168102</td>\n",
       "      <td>88.115636</td>\n",
       "      <td>1182.607935</td>\n",
       "      <td>13.197051</td>\n",
       "      <td>0.367214</td>\n",
       "      <td>0.785362</td>\n",
       "      <td>6.415409</td>\n",
       "      <td>354.974158</td>\n",
       "      <td>725.282172</td>\n",
       "      <td>105.078831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.038977</td>\n",
       "      <td>114.094530</td>\n",
       "      <td>4999.354600</td>\n",
       "      <td>29.384528</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>0.170014</td>\n",
       "      <td>81.630229</td>\n",
       "      <td>1302.946891</td>\n",
       "      <td>1912.952788</td>\n",
       "      <td>162.250784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>2.111000</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.680500</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>5.111000</td>\n",
       "      <td>0.337000</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>13.309500</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>698.500000</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>143993.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4955.000000</td>\n",
       "      <td>33017.000000</td>\n",
       "      <td>46133.000000</td>\n",
       "      <td>3212.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height       lenght           area        eccen      p_black  \\\n",
       "count  3831.000000  3831.000000    3831.000000  3831.000000  3831.000000   \n",
       "mean     10.168102    88.115636    1182.607935    13.197051     0.367214   \n",
       "std      14.038977   114.094530    4999.354600    29.384528     0.176054   \n",
       "min       1.000000     1.000000       7.000000     0.007000     0.052000   \n",
       "25%       7.000000    17.000000     112.000000     2.111000     0.261000   \n",
       "50%       8.000000    40.000000     320.000000     5.111000     0.337000   \n",
       "75%      10.000000   104.000000     960.000000    13.309500     0.424000   \n",
       "max     311.000000   553.000000  143993.000000   413.000000     1.000000   \n",
       "\n",
       "             p_and      mean_tr      blackpix      blackand     wb_trans  \n",
       "count  3831.000000  3831.000000   3831.000000   3831.000000  3831.000000  \n",
       "mean      0.785362     6.415409    354.974158    725.282172   105.078831  \n",
       "std       0.170014    81.630229   1302.946891   1912.952788   162.250784  \n",
       "min       0.062000     1.000000      7.000000      7.000000     1.000000  \n",
       "25%       0.680500     1.610000     42.000000     94.000000    17.000000  \n",
       "50%       0.804000     2.070000    105.000000    246.000000    48.000000  \n",
       "75%       0.925000     2.990000    278.000000    698.500000   123.000000  \n",
       "max       1.000000  4955.000000  33017.000000  46133.000000  3212.000000  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(scale.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scale.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a MLPClassifier with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = utils.np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(200, activation='relu', input_dim=10))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(300, activation='relu'))\n",
    "model.add(layers.Dense(300, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/320\n",
      "3831/3831 [==============================] - 1s 324us/step - loss: 0.7003 - acc: 0.8815\n",
      "Epoch 2/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.2298 - acc: 0.9441\n",
      "Epoch 3/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.1559 - acc: 0.9488\n",
      "Epoch 4/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.1206 - acc: 0.9661\n",
      "Epoch 5/320\n",
      "3831/3831 [==============================] - 0s 69us/step - loss: 0.1094 - acc: 0.9668\n",
      "Epoch 6/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0993 - acc: 0.9697\n",
      "Epoch 7/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0901 - acc: 0.9721\n",
      "Epoch 8/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0880 - acc: 0.9734\n",
      "Epoch 9/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0868 - acc: 0.9713\n",
      "Epoch 10/320\n",
      "3831/3831 [==============================] - 0s 69us/step - loss: 0.0850 - acc: 0.9731\n",
      "Epoch 11/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0868 - acc: 0.9726\n",
      "Epoch 12/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0818 - acc: 0.9734\n",
      "Epoch 13/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0883 - acc: 0.9718\n",
      "Epoch 14/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0789 - acc: 0.9726\n",
      "Epoch 15/320\n",
      "3831/3831 [==============================] - 0s 74us/step - loss: 0.0755 - acc: 0.9734\n",
      "Epoch 16/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0795 - acc: 0.9742\n",
      "Epoch 17/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0780 - acc: 0.9736\n",
      "Epoch 18/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0718 - acc: 0.9757\n",
      "Epoch 19/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0730 - acc: 0.9768\n",
      "Epoch 20/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0741 - acc: 0.9757\n",
      "Epoch 21/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0709 - acc: 0.9762\n",
      "Epoch 22/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0686 - acc: 0.9757\n",
      "Epoch 23/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0693 - acc: 0.9765\n",
      "Epoch 24/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0863 - acc: 0.9731\n",
      "Epoch 25/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0751 - acc: 0.9768\n",
      "Epoch 26/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0696 - acc: 0.9783\n",
      "Epoch 27/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0667 - acc: 0.9760\n",
      "Epoch 28/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0659 - acc: 0.9783\n",
      "Epoch 29/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0625 - acc: 0.9794\n",
      "Epoch 30/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0615 - acc: 0.9786\n",
      "Epoch 31/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0658 - acc: 0.9783\n",
      "Epoch 32/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0628 - acc: 0.9768\n",
      "Epoch 33/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0652 - acc: 0.9783\n",
      "Epoch 34/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0653 - acc: 0.9765\n",
      "Epoch 35/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0606 - acc: 0.9781\n",
      "Epoch 36/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0574 - acc: 0.9799\n",
      "Epoch 37/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0580 - acc: 0.9786\n",
      "Epoch 38/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0623 - acc: 0.9802\n",
      "Epoch 39/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0612 - acc: 0.9794\n",
      "Epoch 40/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0618 - acc: 0.9789\n",
      "Epoch 41/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0593 - acc: 0.9783\n",
      "Epoch 42/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0603 - acc: 0.9791\n",
      "Epoch 43/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0592 - acc: 0.9804\n",
      "Epoch 44/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0580 - acc: 0.9802\n",
      "Epoch 45/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0534 - acc: 0.9817\n",
      "Epoch 46/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0541 - acc: 0.9794\n",
      "Epoch 47/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0534 - acc: 0.9825\n",
      "Epoch 48/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0590 - acc: 0.9781\n",
      "Epoch 49/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0651 - acc: 0.9768\n",
      "Epoch 50/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0558 - acc: 0.9825\n",
      "Epoch 51/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0484 - acc: 0.9828\n",
      "Epoch 52/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0518 - acc: 0.9807\n",
      "Epoch 53/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0513 - acc: 0.9828\n",
      "Epoch 54/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0498 - acc: 0.9830\n",
      "Epoch 55/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0552 - acc: 0.9794\n",
      "Epoch 56/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0519 - acc: 0.9828\n",
      "Epoch 57/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0511 - acc: 0.9815\n",
      "Epoch 58/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0486 - acc: 0.9825\n",
      "Epoch 59/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0530 - acc: 0.9823\n",
      "Epoch 60/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0489 - acc: 0.9830\n",
      "Epoch 61/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0512 - acc: 0.9828\n",
      "Epoch 62/320\n",
      "3831/3831 [==============================] - 0s 56us/step - loss: 0.0555 - acc: 0.9796\n",
      "Epoch 63/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0513 - acc: 0.9823\n",
      "Epoch 64/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0614 - acc: 0.9786\n",
      "Epoch 65/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0557 - acc: 0.9820\n",
      "Epoch 66/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0557 - acc: 0.9789\n",
      "Epoch 67/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0716 - acc: 0.9778\n",
      "Epoch 68/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0701 - acc: 0.9773\n",
      "Epoch 69/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0519 - acc: 0.9828\n",
      "Epoch 70/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0476 - acc: 0.9830\n",
      "Epoch 71/320\n",
      "3831/3831 [==============================] - 0s 56us/step - loss: 0.0490 - acc: 0.9804\n",
      "Epoch 72/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0470 - acc: 0.9815\n",
      "Epoch 73/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0461 - acc: 0.9836\n",
      "Epoch 74/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0457 - acc: 0.9828\n",
      "Epoch 75/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0514 - acc: 0.9838\n",
      "Epoch 76/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0453 - acc: 0.9849\n",
      "Epoch 77/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0402 - acc: 0.9864\n",
      "Epoch 78/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0408 - acc: 0.9851\n",
      "Epoch 79/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0427 - acc: 0.9851\n",
      "Epoch 80/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0451 - acc: 0.9830\n",
      "Epoch 81/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0395 - acc: 0.9851\n",
      "Epoch 82/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0392 - acc: 0.9859\n",
      "Epoch 83/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0458 - acc: 0.9828\n",
      "Epoch 84/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0450 - acc: 0.9838\n",
      "Epoch 85/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0407 - acc: 0.9862\n",
      "Epoch 86/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0415 - acc: 0.9862\n",
      "Epoch 87/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0375 - acc: 0.9869\n",
      "Epoch 88/320\n",
      "3831/3831 [==============================] - 0s 56us/step - loss: 0.0396 - acc: 0.9851\n",
      "Epoch 89/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0411 - acc: 0.9843\n",
      "Epoch 90/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0377 - acc: 0.9862\n",
      "Epoch 91/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0467 - acc: 0.9823\n",
      "Epoch 92/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0381 - acc: 0.9869\n",
      "Epoch 93/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0381 - acc: 0.9864\n",
      "Epoch 94/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0392 - acc: 0.9862\n",
      "Epoch 95/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0428 - acc: 0.9843\n",
      "Epoch 96/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0402 - acc: 0.9859\n",
      "Epoch 97/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0413 - acc: 0.9833\n",
      "Epoch 98/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0513 - acc: 0.9794\n",
      "Epoch 99/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0410 - acc: 0.9862\n",
      "Epoch 100/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0431 - acc: 0.9841\n",
      "Epoch 101/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0385 - acc: 0.9862\n",
      "Epoch 102/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0343 - acc: 0.9893\n",
      "Epoch 103/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0371 - acc: 0.9862\n",
      "Epoch 104/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0375 - acc: 0.9851\n",
      "Epoch 105/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0334 - acc: 0.9880\n",
      "Epoch 106/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0374 - acc: 0.9875\n",
      "Epoch 107/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0425 - acc: 0.9841\n",
      "Epoch 108/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0373 - acc: 0.9862\n",
      "Epoch 109/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0379 - acc: 0.9862\n",
      "Epoch 110/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0390 - acc: 0.9849\n",
      "Epoch 111/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0398 - acc: 0.9862\n",
      "Epoch 112/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0365 - acc: 0.9875\n",
      "Epoch 113/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0372 - acc: 0.9867\n",
      "Epoch 114/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0414 - acc: 0.9864\n",
      "Epoch 115/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0359 - acc: 0.9869\n",
      "Epoch 116/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0380 - acc: 0.9849\n",
      "Epoch 117/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0367 - acc: 0.9859\n",
      "Epoch 118/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0405 - acc: 0.9856\n",
      "Epoch 119/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 120/320\n",
      "3831/3831 [==============================] - 0s 86us/step - loss: 0.0324 - acc: 0.9903\n",
      "Epoch 121/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0335 - acc: 0.9901\n",
      "Epoch 122/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0325 - acc: 0.9898\n",
      "Epoch 123/320\n",
      "3831/3831 [==============================] - 0s 78us/step - loss: 0.0357 - acc: 0.9872\n",
      "Epoch 124/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0338 - acc: 0.9883\n",
      "Epoch 125/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0370 - acc: 0.9877\n",
      "Epoch 126/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0397 - acc: 0.9869\n",
      "Epoch 127/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0321 - acc: 0.9885\n",
      "Epoch 128/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0324 - acc: 0.9872\n",
      "Epoch 129/320\n",
      "3831/3831 [==============================] - 0s 81us/step - loss: 0.0369 - acc: 0.9862\n",
      "Epoch 130/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0402 - acc: 0.9867\n",
      "Epoch 131/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0367 - acc: 0.9864\n",
      "Epoch 132/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0320 - acc: 0.9898\n",
      "Epoch 133/320\n",
      "3831/3831 [==============================] - 0s 82us/step - loss: 0.0307 - acc: 0.9898\n",
      "Epoch 134/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0360 - acc: 0.9880\n",
      "Epoch 135/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0353 - acc: 0.9893\n",
      "Epoch 136/320\n",
      "3831/3831 [==============================] - 0s 84us/step - loss: 0.0285 - acc: 0.9914\n",
      "Epoch 137/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0274 - acc: 0.9909\n",
      "Epoch 138/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0281 - acc: 0.9906\n",
      "Epoch 139/320\n",
      "3831/3831 [==============================] - 0s 76us/step - loss: 0.0275 - acc: 0.9914\n",
      "Epoch 140/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0277 - acc: 0.9906\n",
      "Epoch 141/320\n",
      "3831/3831 [==============================] - 0s 75us/step - loss: 0.0361 - acc: 0.9880\n",
      "Epoch 142/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0392 - acc: 0.9867\n",
      "Epoch 143/320\n",
      "3831/3831 [==============================] - 0s 90us/step - loss: 0.0296 - acc: 0.9898\n",
      "Epoch 144/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0352 - acc: 0.9872\n",
      "Epoch 145/320\n",
      "3831/3831 [==============================] - 0s 87us/step - loss: 0.0345 - acc: 0.9875\n",
      "Epoch 146/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0334 - acc: 0.9890\n",
      "Epoch 147/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0277 - acc: 0.9893\n",
      "Epoch 148/320\n",
      "3831/3831 [==============================] - 0s 69us/step - loss: 0.0305 - acc: 0.9896\n",
      "Epoch 149/320\n",
      "3831/3831 [==============================] - 0s 78us/step - loss: 0.0296 - acc: 0.9896\n",
      "Epoch 150/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0309 - acc: 0.9903\n",
      "Epoch 151/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0369 - acc: 0.9893\n",
      "Epoch 152/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0378 - acc: 0.9883\n",
      "Epoch 153/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0425 - acc: 0.9880\n",
      "Epoch 154/320\n",
      "3831/3831 [==============================] - 0s 87us/step - loss: 0.0448 - acc: 0.9856\n",
      "Epoch 155/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0443 - acc: 0.9883\n",
      "Epoch 156/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0440 - acc: 0.9872\n",
      "Epoch 157/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0461 - acc: 0.9836\n",
      "Epoch 158/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0418 - acc: 0.9862\n",
      "Epoch 159/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0329 - acc: 0.9901\n",
      "Epoch 160/320\n",
      "3831/3831 [==============================] - 0s 86us/step - loss: 0.0298 - acc: 0.9916\n",
      "Epoch 161/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0316 - acc: 0.9898\n",
      "Epoch 162/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0369 - acc: 0.9872\n",
      "Epoch 163/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0353 - acc: 0.9867\n",
      "Epoch 164/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0333 - acc: 0.9896\n",
      "Epoch 165/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0308 - acc: 0.9890\n",
      "Epoch 166/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0302 - acc: 0.9893\n",
      "Epoch 167/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0352 - acc: 0.9893\n",
      "Epoch 168/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0318 - acc: 0.9901\n",
      "Epoch 169/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0295 - acc: 0.9875\n",
      "Epoch 170/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0309 - acc: 0.9890\n",
      "Epoch 171/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0292 - acc: 0.9896\n",
      "Epoch 172/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0280 - acc: 0.9903\n",
      "Epoch 173/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0276 - acc: 0.9906\n",
      "Epoch 174/320\n",
      "3831/3831 [==============================] - 0s 57us/step - loss: 0.0247 - acc: 0.9924\n",
      "Epoch 175/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0248 - acc: 0.9924\n",
      "Epoch 176/320\n",
      "3831/3831 [==============================] - 0s 69us/step - loss: 0.0260 - acc: 0.9919\n",
      "Epoch 177/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0286 - acc: 0.9911\n",
      "Epoch 178/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0296 - acc: 0.9901\n",
      "Epoch 179/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0305 - acc: 0.9903\n",
      "Epoch 180/320\n",
      "3831/3831 [==============================] - 0s 69us/step - loss: 0.0338 - acc: 0.9883\n",
      "Epoch 181/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 182/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0266 - acc: 0.9919\n",
      "Epoch 183/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0239 - acc: 0.9922\n",
      "Epoch 184/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0245 - acc: 0.9919\n",
      "Epoch 185/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0247 - acc: 0.9919\n",
      "Epoch 186/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0269 - acc: 0.9911\n",
      "Epoch 187/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 188/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0301 - acc: 0.9901\n",
      "Epoch 189/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0285 - acc: 0.9906\n",
      "Epoch 190/320\n",
      "3831/3831 [==============================] - 0s 75us/step - loss: 0.0262 - acc: 0.9916\n",
      "Epoch 191/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0302 - acc: 0.9896\n",
      "Epoch 192/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0335 - acc: 0.9875\n",
      "Epoch 193/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0329 - acc: 0.9898\n",
      "Epoch 194/320\n",
      "3831/3831 [==============================] - 0s 82us/step - loss: 0.0306 - acc: 0.9896\n",
      "Epoch 195/320\n",
      "3831/3831 [==============================] - 0s 74us/step - loss: 0.0308 - acc: 0.9898\n",
      "Epoch 196/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0348 - acc: 0.9914\n",
      "Epoch 197/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 198/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0227 - acc: 0.9927\n",
      "Epoch 199/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0224 - acc: 0.9930\n",
      "Epoch 200/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0236 - acc: 0.9916\n",
      "Epoch 201/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0256 - acc: 0.9922\n",
      "Epoch 202/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0228 - acc: 0.9930\n",
      "Epoch 203/320\n",
      "3831/3831 [==============================] - 0s 74us/step - loss: 0.0243 - acc: 0.9919\n",
      "Epoch 204/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0274 - acc: 0.9911\n",
      "Epoch 205/320\n",
      "3831/3831 [==============================] - 0s 81us/step - loss: 0.0240 - acc: 0.9914\n",
      "Epoch 206/320\n",
      "3831/3831 [==============================] - 0s 77us/step - loss: 0.0236 - acc: 0.9909\n",
      "Epoch 207/320\n",
      "3831/3831 [==============================] - 0s 74us/step - loss: 0.0376 - acc: 0.9893\n",
      "Epoch 208/320\n",
      "3831/3831 [==============================] - 0s 85us/step - loss: 0.0289 - acc: 0.9909\n",
      "Epoch 209/320\n",
      "3831/3831 [==============================] - 0s 75us/step - loss: 0.0320 - acc: 0.9898\n",
      "Epoch 210/320\n",
      "3831/3831 [==============================] - 0s 79us/step - loss: 0.0320 - acc: 0.9883\n",
      "Epoch 211/320\n",
      "3831/3831 [==============================] - 0s 79us/step - loss: 0.0272 - acc: 0.9916\n",
      "Epoch 212/320\n",
      "3831/3831 [==============================] - 0s 81us/step - loss: 0.0267 - acc: 0.9909\n",
      "Epoch 213/320\n",
      "3831/3831 [==============================] - 0s 77us/step - loss: 0.0244 - acc: 0.9922\n",
      "Epoch 214/320\n",
      "3831/3831 [==============================] - 0s 82us/step - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 215/320\n",
      "3831/3831 [==============================] - 0s 82us/step - loss: 0.0308 - acc: 0.9896\n",
      "Epoch 216/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0386 - acc: 0.9872\n",
      "Epoch 217/320\n",
      "3831/3831 [==============================] - 0s 77us/step - loss: 0.0418 - acc: 0.9856\n",
      "Epoch 218/320\n",
      "3831/3831 [==============================] - 0s 80us/step - loss: 0.0344 - acc: 0.9877\n",
      "Epoch 219/320\n",
      "3831/3831 [==============================] - 0s 82us/step - loss: 0.0256 - acc: 0.9916\n",
      "Epoch 220/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0226 - acc: 0.9924\n",
      "Epoch 221/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0228 - acc: 0.9927\n",
      "Epoch 222/320\n",
      "3831/3831 [==============================] - 0s 77us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 223/320\n",
      "3831/3831 [==============================] - 0s 85us/step - loss: 0.0227 - acc: 0.9940\n",
      "Epoch 224/320\n",
      "3831/3831 [==============================] - 0s 86us/step - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 225/320\n",
      "3831/3831 [==============================] - 0s 75us/step - loss: 0.0240 - acc: 0.9927\n",
      "Epoch 226/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0259 - acc: 0.9909\n",
      "Epoch 227/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0228 - acc: 0.9930\n",
      "Epoch 228/320\n",
      "3831/3831 [==============================] - 0s 71us/step - loss: 0.0229 - acc: 0.9927\n",
      "Epoch 229/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0247 - acc: 0.9919\n",
      "Epoch 230/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0255 - acc: 0.9919\n",
      "Epoch 231/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0257 - acc: 0.9922\n",
      "Epoch 232/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0246 - acc: 0.9919\n",
      "Epoch 233/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0209 - acc: 0.9940\n",
      "Epoch 234/320\n",
      "3831/3831 [==============================] - 0s 74us/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 235/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0194 - acc: 0.9937\n",
      "Epoch 236/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0196 - acc: 0.9932\n",
      "Epoch 237/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0205 - acc: 0.9940\n",
      "Epoch 238/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0215 - acc: 0.9924\n",
      "Epoch 239/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0225 - acc: 0.9930\n",
      "Epoch 240/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0199 - acc: 0.9924\n",
      "Epoch 241/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0189 - acc: 0.9937\n",
      "Epoch 242/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0229 - acc: 0.9924\n",
      "Epoch 243/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0290 - acc: 0.9906\n",
      "Epoch 244/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0233 - acc: 0.9924\n",
      "Epoch 245/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0276 - acc: 0.9911\n",
      "Epoch 246/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0381 - acc: 0.9885\n",
      "Epoch 247/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0278 - acc: 0.9901\n",
      "Epoch 248/320\n",
      "3831/3831 [==============================] - 0s 87us/step - loss: 0.0263 - acc: 0.9906\n",
      "Epoch 249/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0258 - acc: 0.9914\n",
      "Epoch 250/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0211 - acc: 0.9924\n",
      "Epoch 251/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 252/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0200 - acc: 0.9935\n",
      "Epoch 253/320\n",
      "3831/3831 [==============================] - 0s 72us/step - loss: 0.0238 - acc: 0.9916\n",
      "Epoch 254/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0214 - acc: 0.9916\n",
      "Epoch 255/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 256/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0215 - acc: 0.9932\n",
      "Epoch 257/320\n",
      "3831/3831 [==============================] - 0s 78us/step - loss: 0.0196 - acc: 0.9919\n",
      "Epoch 258/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0240 - acc: 0.9930\n",
      "Epoch 259/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0234 - acc: 0.9932\n",
      "Epoch 260/320\n",
      "3831/3831 [==============================] - 0s 81us/step - loss: 0.0232 - acc: 0.9932\n",
      "Epoch 261/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0245 - acc: 0.9911\n",
      "Epoch 262/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0295 - acc: 0.9906\n",
      "Epoch 263/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0503 - acc: 0.9888\n",
      "Epoch 264/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0504 - acc: 0.9846\n",
      "Epoch 265/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0288 - acc: 0.9896\n",
      "Epoch 266/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0245 - acc: 0.9916\n",
      "Epoch 267/320\n",
      "3831/3831 [==============================] - 0s 76us/step - loss: 0.0204 - acc: 0.9943\n",
      "Epoch 268/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0481 - acc: 0.9901\n",
      "Epoch 269/320\n",
      "3831/3831 [==============================] - 0s 66us/step - loss: 0.0261 - acc: 0.9906\n",
      "Epoch 270/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0237 - acc: 0.9930\n",
      "Epoch 271/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0213 - acc: 0.9932\n",
      "Epoch 272/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0220 - acc: 0.9919\n",
      "Epoch 273/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0218 - acc: 0.9927\n",
      "Epoch 274/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0260 - acc: 0.9909\n",
      "Epoch 275/320\n",
      "3831/3831 [==============================] - 0s 92us/step - loss: 0.0256 - acc: 0.9911\n",
      "Epoch 276/320\n",
      "3831/3831 [==============================] - 0s 78us/step - loss: 0.0261 - acc: 0.9898\n",
      "Epoch 277/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0241 - acc: 0.9930\n",
      "Epoch 278/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0202 - acc: 0.9930\n",
      "Epoch 279/320\n",
      "3831/3831 [==============================] - 0s 76us/step - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 280/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0230 - acc: 0.9937\n",
      "Epoch 281/320\n",
      "3831/3831 [==============================] - 0s 67us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 282/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0191 - acc: 0.9940\n",
      "Epoch 283/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0195 - acc: 0.9935\n",
      "Epoch 284/320\n",
      "3831/3831 [==============================] - 0s 78us/step - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 285/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0182 - acc: 0.9943\n",
      "Epoch 286/320\n",
      "3831/3831 [==============================] - 0s 81us/step - loss: 0.0169 - acc: 0.9948\n",
      "Epoch 287/320\n",
      "3831/3831 [==============================] - 0s 73us/step - loss: 0.0165 - acc: 0.9953\n",
      "Epoch 288/320\n",
      "3831/3831 [==============================] - 0s 70us/step - loss: 0.0202 - acc: 0.9937\n",
      "Epoch 289/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0185 - acc: 0.9937\n",
      "Epoch 290/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0165 - acc: 0.9937\n",
      "Epoch 291/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 292/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0212 - acc: 0.9914\n",
      "Epoch 293/320\n",
      "3831/3831 [==============================] - 0s 68us/step - loss: 0.0214 - acc: 0.9940\n",
      "Epoch 294/320\n",
      "3831/3831 [==============================] - 0s 64us/step - loss: 0.0225 - acc: 0.9916\n",
      "Epoch 295/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0194 - acc: 0.9924\n",
      "Epoch 296/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 297/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0220 - acc: 0.9924\n",
      "Epoch 298/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0210 - acc: 0.9930\n",
      "Epoch 299/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0200 - acc: 0.9937\n",
      "Epoch 300/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0206 - acc: 0.9940\n",
      "Epoch 301/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0246 - acc: 0.9924\n",
      "Epoch 302/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0242 - acc: 0.9916\n",
      "Epoch 303/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0306 - acc: 0.9903\n",
      "Epoch 304/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0347 - acc: 0.9893\n",
      "Epoch 305/320\n",
      "3831/3831 [==============================] - 0s 62us/step - loss: 0.0338 - acc: 0.9883\n",
      "Epoch 306/320\n",
      "3831/3831 [==============================] - 0s 63us/step - loss: 0.0299 - acc: 0.9916\n",
      "Epoch 307/320\n",
      "3831/3831 [==============================] - 0s 65us/step - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 308/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0198 - acc: 0.9930\n",
      "Epoch 309/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0327 - acc: 0.9927\n",
      "Epoch 310/320\n",
      "3831/3831 [==============================] - 0s 61us/step - loss: 0.0246 - acc: 0.9927\n",
      "Epoch 311/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0189 - acc: 0.9937\n",
      "Epoch 312/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0167 - acc: 0.9950\n",
      "Epoch 313/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0174 - acc: 0.9935\n",
      "Epoch 314/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 315/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0161 - acc: 0.9945\n",
      "Epoch 316/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0327 - acc: 0.9901\n",
      "Epoch 317/320\n",
      "3831/3831 [==============================] - 0s 59us/step - loss: 0.0329 - acc: 0.9896\n",
      "Epoch 318/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0478 - acc: 0.9859\n",
      "Epoch 319/320\n",
      "3831/3831 [==============================] - 0s 58us/step - loss: 0.0420 - acc: 0.9877\n",
      "Epoch 320/320\n",
      "3831/3831 [==============================] - 0s 60us/step - loss: 0.0704 - acc: 0.9864\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train_scaled, y_train_oh, epochs=320, workers=-1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keras = model.predict_classes(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4e67caac10>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.epoch, hist.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keras = model.predict_classes(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict_classes(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.99      1.00      3447\n",
      "         2.0       0.94      0.99      0.96       223\n",
      "         3.0       0.84      0.89      0.86        18\n",
      "         4.0       0.94      0.89      0.92        57\n",
      "         5.0       0.85      0.99      0.91        86\n",
      "\n",
      "    accuracy                           0.99      3831\n",
      "   macro avg       0.91      0.95      0.93      3831\n",
      "weighted avg       0.99      0.99      0.99      3831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
