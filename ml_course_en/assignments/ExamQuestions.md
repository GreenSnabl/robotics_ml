1. Lineare Regression. Kostenfunktion. Gradient.
2. Logistische Regression. Kostenfunktion. Gradient.
3. Regularisierung der linearen Regressionsparameter. Lasso-Methode.
4. Regularisierung der linearen Regressionsparameter. Ridge Regression.
5. Grundlagen neuronaler Netze. Backpropagation.
6. Faltungsnetzwerke. Training, Verwendung.
7. Skalierung.
8. Probleme des Overfitting und Underfitting beim maschinellen Lernen.
9. Die Wahl der Parameter und die Architektur der neuronalen Netze.
10. Bewertung von Modellparametern beim maschinellen Lernen (Precision, Recall, F1). Asymmetrische Klassen.
11. Die F채higkeit neuronaler Netze, Funktionen zu approximieren (z. B. XNOR 체ber AND, OR, NOT).
12. Datenvorverarbeitung. Probleme, Ans채tze, Methoden.
13. Evaluierung maschineller Lernmodelle. (Validation Curves, Learning Curves) 
    Ans채tze zur Verbesserung der Genauigkeit von Modellen.
14. Clustering von Daten. K-Means Algorithmus.
15. Methoden zur Dimensionsreduzierung. Prinzipanalyse von Bauteilen.