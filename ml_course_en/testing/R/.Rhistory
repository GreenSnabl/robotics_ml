knn.fit$finalModel
?caret::train
knn.fit <- caret::train(churn ~ .,
data=df.train,
y=df.train$churn,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit <- caret::train(churn ~ .,
data=df.train,
y=df.train$churn,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
summary(knn.fit$finalModel)
summary(knn.fit)
plot(knn.fit)
knn.fit$finalModel
knn.grid <- expand.grid(k = seq(1:20))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit
summary(knn.fit)
plot(knn.fit)
knn.fit$finalModel
knn.grid <- expand.grid(k = seq(1,50, 5))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit
summary(knn.fit)
plot(knn.fit)
knn.fit$finalModel
knn.grid <- expand.grid(k = seq(1,100,105))
knn.grid <- expand.grid(k = seq(1,100,10))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit
summary(knn.fit)
plot(knn.fit)
knn.fit$finalModel
data=df.train,
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("accuracy","ROC"))
knn.fit
summary(knn.fit)
plot(knn.fit)
knn.fit$finalModel
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("accuracy"))
?caret::train
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("Accuracy"))
knn.grid <- expand.grid(k = seq(1,10,10))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("Accuracy"))
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
classProbs = TRUE)
knn.grid <- expand.grid(k = seq(1,10,10))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("Accuracy"))
knn.fit
plot(knn.fit)
knn.fit
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("Accuracy", "ROC"))
knn.fit <- caret::train(churn ~ .,
data=df.train,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric=c("ROC"))
str(df)
str(df.train)
df.train.scaled <- df.train
df.train.scaled[,names(df.train.scaled) != "churn"] <-
lapply(df.train.scaled, scale)
df.train.scaled[,names(df.train.scaled) != "churn"] <-
lapply(df.train.scaled[, names(df.train.scaled) != "churn"], scale)
knn.grid <- expand.grid(k = seq(1,100,10))
knn.fit <- caret::train(churn ~ .,
data=df.train.scaled,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit
knn.grid <- expand.grid(k = seq(1,10))
knn.fit <- caret::train(churn ~ .,
data=df.train.scaled,
method = "knn",
tuneGrid=knn.grid,
trControl=ctrl,
metric="ROC")
knn.fit
rpart.fit2
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
#summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit2 <- caret::train(churn ~ .,
data=df.train,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
metric="Accuracy")
rpart.fit2
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit2 <- caret::train(churn ~ .,
data=df.train,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
metric="Accuracy")
rpart.fit2
fancyRpartPlot(rpart.fit2$finalModel)
predictandCM(rpart.fit2$finalModel, df.test)
predictandCM(rpart.fit2$finalModel, df.train)
rpart.fit2 <- caret::train(churn ~ .,
data=df.train,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15
metric="Accuracy")
rpart.fit2 <- caret::train(churn ~ .,
data=df.train,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="Accuracy")
rpart.fit2
fancyRpartPlot(rpart.fit2$finalModel)
predictandCM(rpart.fit2$finalModel, df.train)
predictandCM(rpart.fit2$finalModel, df.test)
predictandCM(rpart.fit2$finalModel, df.train)
?rfeControl
ctrl <- rfeControl(functions = treebagFuncs,
method="repeatedcv",
number=10,
repeats=3,
summaryFunction=twoClassSummary,
classProbs=TRUE)
?rfe
ctrl <- rfeControl(functions = treebagFuncs,
method="repeatedcv",
number=10,
repeats=3,
summaryFunction=twoClassSummary)
ctrl <- rfeControl(functions = treebagFuncs,
method="repeatedcv",
number=10,
repeats=3)
rfe(churn ~ ., data=df.train, rfeControl=ctrl=)
rfe(churn ~ ., data=df.train, rfeControl=ctrl)
rfe(churn ~ ., data=df.train, rfeControl=ctrl, metric="ROC")
caretFuncs$summary <- twoClassSummary
ctrl <- rfeControl(functions=caretFuncs,
method = "repeatedcv",
repeats =5, number = 10,
returnResamp="final", verbose = TRUE)
trainctrl <- trainControl(classProbs= TRUE,
summaryFunction = twoClassSummary)
tree.fit2 <- rfe(churn ~ ., data=df.train,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(df.train[,1:length(df.train)-1], df$churn
data=df.train,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(df.train[,1:length(df.train)-1], df$churn,
data=df.train,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(df.train[,1:length(df.train)-1],
df$churn,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(df.train[,1:length(df.train)-1],
df.train$churn,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
df.train[,1:length(df.train)-1]
tree.fit2 <- rfe(df.train[,1:(length(df.train)-1)],
df.train$churn,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit2 <- caret::train(churn ~ .,
data=df.train,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
caretFuncs$summary <- twoClassSummary
ctrl <- rfeControl(functions=caretFuncs,
method = "repeatedcv",
repeats =5, number = 10,
returnResamp="final", verbose = TRUE)
trainctrl <- trainControl(classProbs= TRUE,
summaryFunction = twoClassSummary)
df.train[,1:length(df.train)-1]
length(df.train)
df.train[,1:18]
tree.fit2 <- rfe(df.train[,1:18],
df.train$churn,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(df.train,
df.train$churn,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
tree.fit2 <- rfe(churn ~ ., df.train,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
warnings()
df.train
str(df.train)
df$churn <- as.factor(df$churn)
summary(df)
state <- df$state
# 70/30 split
set.seed(1)
indexes <- createDataPartition(df$churn, p = 0.7, list=F)
df.train <- df[indexes,]
df.test <- df[-indexes,]
caretFuncs$summary <- twoClassSummary
ctrl <- rfeControl(functions=caretFuncs,
method = "repeatedcv",
repeats =5, number = 10,
returnResamp="final", verbose = TRUE)
trainctrl <- trainControl(classProbs= TRUE,
summaryFunction = twoClassSummary)
str(df.train)
tree.fit2 <- rfe(churn ~ .,
df.train,
rfeControl=ctrl,
method="rpart2",
## I also added this line to
## avoid a warning:
metric = "ROC",
trControl = trainctrl)
caretFuncs$summary <- twoClassSummary
ctrl <- rfeControl(functions=caretFuncs,
method = "repeatedcv",
repeats =5, number = 10,
returnResamp="final", verbose = TRUE)
trainctrl <- trainControl(classProbs= TRUE,
summaryFunction = twoClassSummary)
str(df.train)
numberofcores = detectCores()  # review what number of cores does for your environment
numberofcores
cl <- makeCluster(numberofcores, type = "SOCK")
registerDoSNOW(cl)
library(doSNOW)
numberofcores = detectCores()  # review what number of cores does for your environment
numberofcores
cl <- makeCluster(numberofcores, type = "SOCK")
registerDoSNOW(cl)
system.time (
tree.fit2 <- rfe(churn ~ .,
df.train,
rfeControl=ctrl,
method="rpart2",
metric = "ROC",
trControl = trainctrl)
)
stopCluster(cl)
tree.fit2
tree.fit2$variables
tree.fit2$results
tree.fit2$bestSubset
tree.fit2$coefnames
tree.fit2$results$Variables
tree.fit2$results$Spec
tree.fit2$results
tree.fit2
tree.fit2$perfNames
tree.fit2$optVariables
best.features <- tree.fit2$optVariables
rpart.fit2 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit2 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
registerDoSEQ()
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit2 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
warnings()
rpart.fit2
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
rpart.fit2
rpart.fit3
predictandCM(rpart.fit3, df.train$churn)
predictandCM(rpart.fit3$bestTune, df.train$churn)
predictandCM(rpart.fit3$finalModel, df.train$churn)
predictandCM(rpart.fit3$finalModel, df.train)
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
predictandCM(rpart.fit3$finalModel, df.train)
caretFuncs$summary <- defaultSummary
ctrl <- rfeControl(functions=caretFuncs,
method = "repeatedcv",
repeats =5,
number = 10,
returnResamp="final", verbose = TRUE)
trainctrl <- trainControl()#classProbs= TRUE,
str(df.train)
numberofcores = detectCores()  # review what number of cores does for your environment
numberofcores
cl <- makeCluster(numberofcores, type = "SOCK")
registerDoSNOW(cl)
system.time (
tree.fit2 <- rfe(churn ~ .,
df.train,
rfeControl=ctrl,
method="rpart2",
metric = "Accuracy",
trControl = trainctrl)
)
stopCluster(cl)
registerDoSEQ()
best.features <- tree.fit2$optVariables
ctrl <- trainControl(method="repeatedcv",
number = 10,
repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
?caret::train
tree.grid <- expand.grid(maxdepth = seq(1,15))
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
predictandCM(rpart.fit3$finalModel, df.train)
warnings()
predictandCM(rpart.fit3$finalModel, df.test)
predictandCM(rpart.fit3$results, df.test)
rpart.fit3$results
rpart.fit3$modelInfo
rpart.fit3$pred
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
test=df.test,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
predictandCM(rpart.fit3$finalModel, df.test)
df.train[, best.features]
source('~/HDD/Programming/Python/hda_Machine_Learning/ml_course_en/testing/R/Chapter_04-01-Classificitation.R', echo=TRUE)
predictandCM(rpart.fit3$finalModel, df.train)
plot(rpart.fit3)
tree.grid <- expand.grid(maxdepth = 6)
rpart.fit3 <- caret::train(df.train[,best.features],
df.train$churn,
method = "rpart2",
tuneGrid=tree.grid,
trControl=ctrl,
tuneLength = 15,
metric="ROC")
predictandCM(rpart.fit3$finalModel, df.test)
predictandCM(rpart.fit3$finalModel, df.train)
plot(rpart.fit3)
